{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/junsu/nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/junsu/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   LS  TO  VBN  ''  WP  UH  VBG  JJ  VBZ  --  ...  CC  CD  POS  \\\n",
       "0   0   0    0   0   1   0    0   0    0   0  ...   0   0    0   \n",
       "1   0   0    0   0   0   0    0   0    0   0  ...   0   0    0   \n",
       "2   0   0    0   0   0   0    0   0    0   0  ...   0   0    0   \n",
       "3   0   0    0   0   1   0    0   0    1   0  ...   0   0    0   \n",
       "4   0   0    0   0   0   0    0   1    1   0  ...   0   0    0   \n",
       "\n",
       "   num_of_unique_punctuations  num_of_capital_words  num_of_small_words  \\\n",
       "0                           0                     1                   4   \n",
       "1                           0                     1                   3   \n",
       "2                           1                     1                   7   \n",
       "3                           1                     1                   3   \n",
       "4                           0                     1                   2   \n",
       "\n",
       "   number_of_alphabets  number_of_digits  number_of_words  \\\n",
       "0                   19                 0                5   \n",
       "1                   18                 0                4   \n",
       "2                   28                 0                9   \n",
       "3                   14                 0                5   \n",
       "4                   13                 0                3   \n",
       "\n",
       "   number_of_white_spaces  \n",
       "0                       4  \n",
       "1                       3  \n",
       "2                       7  \n",
       "3                       3  \n",
       "4                       2  \n",
       "\n",
       "[5 rows x 52 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LS</th>\n      <th>TO</th>\n      <th>VBN</th>\n      <th>''</th>\n      <th>WP</th>\n      <th>UH</th>\n      <th>VBG</th>\n      <th>JJ</th>\n      <th>VBZ</th>\n      <th>--</th>\n      <th>...</th>\n      <th>CC</th>\n      <th>CD</th>\n      <th>POS</th>\n      <th>num_of_unique_punctuations</th>\n      <th>num_of_capital_words</th>\n      <th>num_of_small_words</th>\n      <th>number_of_alphabets</th>\n      <th>number_of_digits</th>\n      <th>number_of_words</th>\n      <th>number_of_white_spaces</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>19</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>28</td>\n      <td>0</td>\n      <td>9</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>14</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 52 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('tagsets')\n",
    "from nltk.data import load\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "\n",
    "data = pd.read_csv('data.csv', header = 0)\n",
    "pos_di = {}\n",
    "for pos in list(tagdict.keys()):\n",
    "    pos_di[pos] = []\n",
    "for doc in data['text']:\n",
    "    di = Counter([j for i, j in pos_tag(word_tokenize(doc))])\n",
    "    for pos in list(tagdict.keys()):\n",
    "        pos_di[pos].append(di[pos])\n",
    "feature_df = pd.DataFrame(pos_di)\n",
    "feature_df['num_of_unique_punctuations'] = data['text'].apply(lambda x : len(set(x).intersection(set(punctuation))))\n",
    "#print(data['text'].apply(lambda x : set(x).intersection(set(punctuation))))\n",
    "feature_df['num_of_capital_words'] = data['text'].apply(lambda x : \\\n",
    "    len([word for word in word_tokenize(str(x)) if word[0].isupper()]))\n",
    "feature_df['num_of_small_words'] = data['text'].apply(lambda x : \\\n",
    "    len([word for word in word_tokenize(str(x)) if word[0].islower()]))\n",
    "feature_df['number_of_alphabets'] = data['text'].apply(lambda x : \\\n",
    "    len([ch for ch in str(x) if ch.isalpha()]))\n",
    "feature_df['number_of_digits'] = data['text'].apply(lambda x : \\\n",
    "    len([ch for ch in str(x) if ch.isdigit()]))\n",
    "feature_df['number_of_words'] = data['text'].apply(lambda x : \\\n",
    "    len(word_tokenize(str(x))))\n",
    "feature_df['number_of_white_spaces'] = data['text'].apply(lambda x : \\\n",
    "    len(str(x).split(' '))-1)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}